{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework IV\n",
    "### Due Date:  11:55 PM, Tuesday, April 24, 2018\n",
    "\n",
    "You should turn in the notebook at Columbia CourseWorks website.\n",
    "\n",
    "Before you turn in the notebook, press the \"Run all cells\" button in the toolbar, and make sure all the calculation results and graphs are produced correctly, and then save the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h3 style=\"color:deepskyblue\">Uncertain Volatility Model 1D</h3>\n",
    "\n",
    "The price of a vanilla payoff $g(X_T)$ on a single asset $X_t$ in the uncertain volatility model satisfies the\n",
    "one dimensional Black-Scholes-Barenblatt (BSB) PDE\n",
    "\\begin{align*}\n",
    "\\partial_tu(t,x)+\\frac{1}{2}x^2\\partial_x^2u(t,x)\\Sigma\\left(\\partial_x^2u(t,x)\\right)^2&=0\\\\\n",
    "u(T,x)&=g(x)\n",
    "\\end{align*}\n",
    "where\n",
    "\\begin{equation*}\n",
    "\\Sigma(\\Gamma)=\\left\\{\\begin{array}\\,\n",
    "\\underline{\\sigma} & \\text{ if }\\Gamma<0\\\\ \\overline{\\sigma} & \\text{ if }\\Gamma\\geq 0\\end{array}\\right.\n",
    "\\end{equation*}\n",
    "For the sake of simplicity, we assume zero interest rate and zero dividend and repo.\n",
    "\n",
    "The BSB PDE is a fully nonlinear second order parabolic PDE which has a stochastic representation by second-oder BSDE. We are free to choose the diffusion for $X$; we pick a lognormal dynamics with some constant volatility $\\hat\\sigma$,\n",
    "\n",
    "$$dX_t=\\hat{\\sigma} X_tdW_t$$\n",
    "\n",
    "Two numerical schemes to solve 2-BSDEs are presented below. We first divide $(0, T)$ into $n$ subintervals $(t_{i-1}, t_i)$, $1\\leq i\\leq n$ and set $\\Delta t_i=t_i-t_{i-1}$ and $\\Delta W_{t_i} = W_{t_i} - W_{t_{i-1}}$.\n",
    "\n",
    "<b>Scheme 1</b>\n",
    "\\begin{align*}\n",
    "Y_{t_n}&=g(X_{t_n})\\\\\n",
    "Z_{t_n}&=g'\\left(X_{t_n}\\right)\\\\\n",
    "Y_{t_{i-1}}&=\\mathbb{E}_{i-1}\\left[Y_{t_i}\\right]+\\frac{1}{2}\\Gamma_{t_{i-1}}X_{t_{i-1}}^2\\left(\\Sigma\\left(\\Gamma_{t_{i-1}}\\right)^2-\\hat{\\sigma}^2\\right)\\Delta t_i\\\\\n",
    "Z_{t_{i-1}}&=\\frac{1}{\\Delta t_i\\sigma X_{t_{i-1}}}\\mathbb{E}_{i-1}\\left[Y_{t_i}\\Delta W_{t_i}\\right]\\\\\n",
    "\\Gamma_{t_{i-1}}&=\\frac{1}{\\Delta t_i\\sigma X_{t_{i-1}}}\\mathbb{E}_{i-1}\\left[Z_{t_i}\\Delta W_{t_i}\\right]\n",
    "\\end{align*}\n",
    "\n",
    "In the second scheme, we introduce explicitly the Malliavin weight for the log-normal diffusion with volatility $\\hat{\\sigma}$, so that $\\Gamma$ can be estimated directly from $Y$ without computing $Z$ in the intermediate step. In particular, there is no need to compute the final condition $Z_{t_n}=g'\\left(X_{t_n}\\right)$. This could be useful to handle non-smooth payoffs.\n",
    "\n",
    "<b>Scheme 2</b>\n",
    "\\begin{align*}\n",
    "Y_{t_n}&=g(X_{t_n})\\\\\n",
    "Y_{t_{i-1}}&=\\mathbb{E}_{i-1}\\left[Y_{t_i}\\right]+\\frac{1}{2}\\Gamma_{t_{i-1}}X_{t_{i-1}}^2\\left(\\Sigma\\left(\\Gamma_{t_{i-1}}\\right)^2-\\hat{\\sigma}^2\\right)\\Delta t_i\\\\\n",
    "\\Gamma_{t_{i-1}}&=\\frac{1}{\\left(\\Delta t_i\\sigma X_{t_{i-1}}\\right)^2}\\mathbb{E}_{i-1}\\left[Y_{t_i}\\left(\\Delta W_{t_i}^2-\\Delta t_i\\left(1+\\hat{\\sigma}\\Delta W_{t_i}\\right)\\right)\\right]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def piecewiselinear_fit(xdata, ydata, knots):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    xdata: array_like\n",
    "        The x-coordinates of the data points.\n",
    "    ydata: array_like\n",
    "        The y-coordinates of the data points.\n",
    "    knots: array_like\n",
    "        Knots of the piecewise linear function, must be increasing.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    res: ndarray\n",
    "        Coefficients of the piecewise linear function\n",
    "    \"\"\"\n",
    "    nknots = len(knots)\n",
    "    diag = np.identity(nknots)\n",
    "    A = np.vstack([np.interp(xdata, knots, diag[i]) for i in range(nknots)]).T\n",
    "    return np.linalg.lstsq(A, ydata)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b style=\"color:darkorange\">Question 1.</b> Consider pricing the call spread $\\frac{100}{K_2-K_1}\\left(\\left(X_T-K_1\\right)^+-\\left(X_T-K_2\\right)^+\\right)$ in the uncertain volatility model, where\n",
    "\n",
    "\\begin{equation*}\n",
    "\\underline{\\sigma}=0.1,\\quad\\overline{\\sigma}=0.2,\\quad X_0=100,\\quad T=1, \\quad K_1 = 90, \\quad K_2 = 110\n",
    "\\end{equation*}\n",
    "\n",
    "For your reference, the true price (from PDE) is $56.0$.\n",
    "\n",
    "<b>(a).</b> An implementation of Scheme 1 outlined above is provided for your convenience.\n",
    "\n",
    "<ul>\n",
    "<li> Experiment with different values of $\\hat\\sigma$, $\\Delta t$, and number of paths. Comment on the results.\n",
    "<li> Describe the region where the gamma is positive (resp. negative).\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "T = 1\n",
    "X0 = 100\n",
    "KL = 90\n",
    "KH = 110\n",
    "volL = 0.1\n",
    "volH = 0.2\n",
    "c = 100./(KH-KL)\n",
    "\n",
    "def g(x):\n",
    "    return c*(np.maximum(x-KL, 0)-np.maximum(x-KH, 0))\n",
    "\n",
    "def Dg(x):\n",
    "    return c*np.asfarray((x >= KL) & (x <= KH))\n",
    "\n",
    "def Sigma(x):\n",
    "    return np.where(x >= 0, volH, volL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.3034628164\n"
     ]
    }
   ],
   "source": [
    "# # # Backward induction to compute Sigma # # #\n",
    "nsteps = 12\n",
    "ts = np.linspace(0, T, nsteps+1)\n",
    "nknots = 15\n",
    "vol = 0.2\n",
    "npaths = 5000\n",
    "dW = np.vstack((np.zeros((1, npaths), dtype=np.float),\n",
    "                np.random.randn(nsteps, npaths) * np.sqrt(np.diff(ts))[:, np.newaxis]))\n",
    "W = np.cumsum(dW, axis=0)\n",
    "X = np.exp(-0.5*vol**2*ts[:, np.newaxis] + vol*W)*X0\n",
    "xps = np.full((len(ts), nknots), np.nan, dtype=np.float)\n",
    "gps = np.full((len(ts), nknots), np.nan, dtype=np.float)\n",
    "Y = g(X[-1])\n",
    "Z = Dg(X[-1])\n",
    "for i in range(len(ts)-2, 0, -1):\n",
    "    dt = ts[i+1] - ts[i]\n",
    "    xps[i] = np.linspace(np.percentile(X[i], 1), np.percentile(X[i], 99), nknots)\n",
    "    yE = np.interp(X[i], xps[i], piecewiselinear_fit(X[i], Y, xps[i]))\n",
    "    gps[i] = piecewiselinear_fit(X[i], Z*dW[i+1]/(dt*vol*X[i]), xps[i])\n",
    "    G = np.interp(X[i], xps[i], gps[i])\n",
    "    Z = np.interp(X[i], xps[i], piecewiselinear_fit(X[i], Y*dW[i+1]/(dt*vol*X[i]), xps[i]))\n",
    "    Y = yE + dt/2*X[i]**2*G*(Sigma(G)**2-vol**2)\n",
    "dt = ts[1]-ts[0]\n",
    "# in the last step of backward induction, the conditional expectations reduce to the mean values \n",
    "G = np.mean(Z*dW[1]/(dt*vol*X0))\n",
    "volp = Sigma(G)\n",
    "\n",
    "# # # independent simulation to get a lower bound price # # #\n",
    "\n",
    "npaths = 2**15\n",
    "# we use more discretization time steps in this second run to simulate accurately the (nearly) optimal X process\n",
    "nsteps = 400\n",
    "Dt = ts[1]-ts[0]\n",
    "ts_ = np.linspace(0, T, nsteps+1)\n",
    "dW = np.vstack((np.zeros((1, npaths), dtype=np.float),\n",
    "                np.random.randn(nsteps, npaths) * np.sqrt(np.diff(ts_))[:, np.newaxis]))\n",
    "X = np.full((len(ts_), npaths), np.nan, dtype=np.float)\n",
    "X[0] = X0\n",
    "m = int(round(ts[1]/(ts_[1]-ts_[0])))\n",
    "for i in range(1, m+1):\n",
    "    dt = ts_[i] - ts_[i-1]\n",
    "    X[i] = X[i-1]*np.exp(-0.5*volp**2*dt+dW[i]*volp)\n",
    "for i in range(m+1, len(ts_)):\n",
    "    dt = ts_[i] - ts_[i-1]\n",
    "    j = int(np.ceil(ts_[i]/Dt))-1\n",
    "    vols = Sigma(np.interp(X[i-1], xps[j], gps[j]))\n",
    "    X[i] = X[i-1]*np.exp(-0.5*vols**2*dt+dW[i]*vols)\n",
    "print(np.mean(g(X[-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>(b).</b> Implement Scheme 2 outlined above to price the call spread. As in part (a), after you obtain estimates of $x\\mapsto\\Gamma\\left(t_i, x\\right)$ at each discretization time $t_i$, re-simulate a new set of independent paths following the process $dX_t = \\Sigma(\\Gamma(t,X_t))X_tdW_t$ to price the call spread, using more time steps. Compare the results of the two schemes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>(c).</b> In schemes 1 and 2, the estimations of the conditional expectations for $Z_{t_{i-1}}$ and $\\Gamma_{t_{i-1}}$ may suffer large variances when $\\Delta t_i$ is small. Control variates can be used to reduce the variance. For example, Scheme 2 can be modified as follows\n",
    "\n",
    "<b>Scheme 2a</b>\n",
    "\\begin{align*}\n",
    "Y_{t_n}&=g(X_{t_n})\\\\\n",
    "Y_{t_{i-1}}&=\\mathbb{E}_{i-1}\\left[Y_{t_i}\\right]+\\frac{1}{2}\\Gamma_{t_{i-1}}X_{t_{i-1}}^2\\left(\\Sigma\\left(\\Gamma_{t_{i-1}}\\right)^2-\\hat{\\sigma}^2\\right)\\Delta t_i\\\\\n",
    "\\Gamma_{t_{i-1}}&=\\frac{1}{\\left(\\Delta t_i\\sigma X_{t_{i-1}}\\right)^2}\\mathbb{E}_{i-1}\\left[\\left(Y_{t_i}-\\mathbb{E}_{i-1}\\left[Y_{t_i}\\right]\\right)\\left(\\Delta W_{t_i}^2-\\Delta t_i\\left(1+\\hat{\\sigma}\\Delta W_{t_i}\\right)\\right)\\right]\n",
    "\\end{align*}\n",
    "Note that $Y_{t_i}$ on the right side of the last equation has been replaced by $Y_{t_{i}}-\\mathbb{E}_{i-1}\\left[Y_{t_i}\\right]$.\n",
    "\n",
    "Explain why this replacement does not change the left hand side. Implement Scheme 2a. Do you observe variance reduction?\n",
    "\n",
    "For a justification of Scheme 2a, see Exercise 2 of the written homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h3 style=\"color:deepskyblue\">The particle Method and Smile Calibration</h3>\n",
    "\n",
    "<b style=\"color:darkorange\">Question 2.</b> Consider the stochastic local volatility (SLV) model\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "dS_t = a_t l(t, S_t) S_t dW^{(1)}_t\\\\\n",
    "d a_t = \\gamma a_t  dW^{(2)}_t\\\\\n",
    "d \\langle W^{(1)}, W^{(2)} \\rangle_t = \\rho dt.\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The numerical values for the model parameters are\n",
    "- $T = 1$.\n",
    "- $S_0 = 100$.\n",
    "- $a_0 = 15\\%$.\n",
    "- $\\rho = -50\\%$.\n",
    "- $\\gamma = 50\\%$.\n",
    "\n",
    "The goal is to find a leverage function $l(t, S)$ so that this model matches the market prices of vanilla options. For the sake of simplicity, we assume that the market implied volatility surface is flat $\\sigma_{\\textrm{Market}} \\equiv 15\\%$. In that case, we also have $\\sigma_{\\textrm{Dup}}(t,S) \\equiv 15\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>(a).</b> Implementation of the Particle Method.\n",
    "- Implement the particle method studied in class to find the leverage function $l$. For this purpose, you may use the non-parametric regression routine provided in the first assignment. We suggest that you use the quartic kernel\n",
    "\n",
    "$$K(x)=(x+1)^2(1-x)^2\\quad\\text{for }-1\\leq x\\leq 1\\quad\\text{and}\\quad0\\quad\\text{ elsewhere}$$\n",
    "\n",
    "together with the bandwidth \n",
    "\n",
    "$$h = \\kappa \\sigma_{\\mathrm{Market}} S_0 \\sqrt{\\max(t_k,0.15)}N^{-0.2}$$\n",
    "\n",
    "at discretization date $t_k$. Make sure to fine-tune the dimensionless bandwidth parameter $\\kappa$. Its order of magnitude is 1.0. Use $\\Delta t = 1/100$, $N=10,000$ paths. Note: In class, we described an acceleration technique that involves sorting the \"particles\" $(S_{t_k},a_{t_k})$ according to the spot value $S_{t_k}$. Since the kernel we have chosen has compact support and is fairly inexpensive to evaluate, you may ignore this acceleration technique here. This means that each estimation of a conditional expectation $\\mathbb{E}[a_{t_k}^2|S_{t_k}=x]$ (for $x$ in a grid of spot values) involves the ratio of two sums of $N$ terms each.\n",
    "\n",
    "- Check that the resulting model is indeed calibrated to the market implied volatilities $\\sigma_{\\textrm{Market}} \\equiv 15\\%$. To this end, compute estimates of the call prices (maturity $T=1$) in the calibrated model for strikes $70, 80, 90, 100, 110, 120, 130, 140$, and invert the Black-Scholes formula to get the corresponding estimation of the implied volatilities $\\hat\\sigma(T,K)$. To estimate the call prices in the calibrated model, simulate a new set of independent paths with the calibrated leverage function $l$ and $N_2 = 100,000$ paths. For the inversion of the Black-Scholes formula, you can use the function <code>blackscholes_impv</code> provided below.\n",
    "\n",
    "<b>(b).</b> Fix the spot-vol correlation $\\rho = 0\\%$. We study the impact of volatility of volatility $\\gamma$ on the smile in the pure stochastic volatility model and calibrated leverage function in the SLV model. Perform the following tasks with various values of $\\gamma$. Suggested values of $\\gamma$: $0\\%$, $25\\%$, $50\\%$, $75\\%$.\n",
    "- Recalibrate the leverage function $l(t,S)$ for each $\\gamma$, and plot the calibrated leverage function $l(t, S)$ as a function of the spot value $S$ for a fixed maturity, e.g., $t = T$ with various values of $\\gamma$ in the same graph. Comment on the dependence of the shape of the leverage function on $\\gamma$.\n",
    "- Plot the corresponding smile at maturity $T$ for the pure stochastic volatility model (set the leverage function $l \\equiv 1$) with the various values of $\\gamma$ in the same graph. Comment on the dependence of the shape of the smile on $\\gamma$.\n",
    "\n",
    "<b>(c).</b> Fix the volatility of volatility $\\gamma = 50\\%$. We study the impact of spot-vol correlation $\\rho$ on the smile in the pure stochastic volatility model and calibrated leverage function in the SLV model. Perform the following tasks with various values of $\\rho$. Suggested values of $\\rho$: $-50\\%$, $0\\%$, $50\\%$.\n",
    "- Recalibrate the leverage function $l(t,S)$ for each $\\rho$, and plot the calibrated leverage function $l(t, S)$ as a function of the spot value $S$ for a fixed maturity, e.g., $t = T$ with various values of $\\rho$ in the same graph. Comment on the dependence of the shape of the leverage function on $\\rho$.\n",
    "- Plot the corresponding smile at maturity $T$ for the pure stochastic volatility model (set the leverage function $l \\equiv 1$) with the various values of $\\rho$ in the same graph. Comment on the dependence of the shape of the smile on $\\rho$.\n",
    "\n",
    "<b>(d).</b> Consider the forward-starting straddle with payoff\n",
    "\\begin{equation*}\n",
    "\\left\\vert \\frac{S_{T_2}}{S_{T_1}}-1 \\right\\vert\n",
    "\\end{equation*}\n",
    "with $T_1 = T - \\frac{3}{12}$, $T_2 = T$. Use $\\gamma = 100\\%$ and $\\rho = -50\\%$. Compare the prices of this option in the Black-Scholes model with volatility 15% and in the calibrated SLV model. Comment on the result. Why is it of interest to use stochastic local volatility models for pricing derivatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def blackscholes_price(K, T, S, vol, r=0, q=0, callput='call'):\n",
    "    \"\"\"Compute the call/put option price in Black-Scholes model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    K: scalar or array_like\n",
    "        The strike of the option.\n",
    "    T: scalar or array_like\n",
    "        The maturity of the option.\n",
    "    S: scalar or array_like\n",
    "        The spot price of the underlying security.\n",
    "    vol: scalar or array_like\n",
    "        The implied Black-Scholes volatility.\n",
    "    callput: str\n",
    "        Must be either 'call' or 'put'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    price: scalar or array_like\n",
    "        The price of the option.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> blackscholes_price(95, 0.25, 100, 0.2, r=0.05, callput='put')\n",
    "    1.5342604771222823\n",
    "    \"\"\"\n",
    "    F = S*np.exp((r-q)*T)\n",
    "    w = vol**2*T\n",
    "    d1 = (np.log(F/K)+0.5*w)/np.sqrt(w)\n",
    "    d2 = d1 - np.sqrt(w)\n",
    "    callput = callput.lower()\n",
    "    if callput == 'call':\n",
    "        opttype = 1\n",
    "    elif callput == 'put':\n",
    "        opttype = -1\n",
    "    else:\n",
    "        raise ValueError('The value of callput must be either \"call\" or \"put\".')\n",
    "    price = (opttype*F*norm.cdf(opttype*d1)-opttype*K*norm.cdf(opttype*(d2)))*np.exp(-r*T)\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.2065480314699341)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all inputs must be scalar\n",
    "def blackscholes_impv_scalar(K, T, S, value, r=0, q=0, callput='call', tol=1e-6, maxiter=500):\n",
    "    \"\"\"Compute implied vol in Black-Scholes model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    K: scalar\n",
    "        The strike of the option.\n",
    "    T: scalar\n",
    "        The maturity of the option.\n",
    "    S: scalar\n",
    "        The spot price of the underlying security.\n",
    "    value: scalar\n",
    "        The value of the option\n",
    "    callput: str\n",
    "        Must be either 'call' or 'put'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vol: scalar\n",
    "        The implied vol of the option.\n",
    "    \"\"\"\n",
    "    if (K <= 0) or (T <= 0):\n",
    "        return np.nan\n",
    "    F = S*np.exp((r-q)*T)\n",
    "    K = K/F\n",
    "    value = value*np.exp(r*T)/F\n",
    "    callput = callput.lower()\n",
    "    if callput not in ['call', 'put']:\n",
    "        raise ValueError('The value of \"callput\" must be either \"call\" or \"put\"')\n",
    "    opttype = 1 if callput == 'call' else -1\n",
    "    value -= max(opttype * (1 - K), 0)\n",
    "    if value < 0:\n",
    "        return np.nan\n",
    "    if (value == 0):\n",
    "        return 0\n",
    "    j = 1\n",
    "    p = np.log(K)\n",
    "    if K >= 1:\n",
    "        x0 = np.sqrt(2 * p)\n",
    "        x1 = x0 - (0.5 - K * norm.cdf(-x0) - value) * np.sqrt(2*np.pi)\n",
    "        while (abs(x0 - x1) > tol*np.sqrt(T)) and (j < maxiter):\n",
    "            x0 = x1\n",
    "            d1 = -p/x1+0.5*x1\n",
    "            x1 = x1 - (norm.cdf(d1) - K*norm.cdf(d1-x1)-value)*np.sqrt(2*np.pi)*np.exp(0.5*d1**2)\n",
    "            j += 1\n",
    "        return x1 / np.sqrt(T)\n",
    "    else:\n",
    "        x0 = np.sqrt(-2 * p)\n",
    "        x1 = x0 - (0.5*K-norm.cdf(-x0)-value)*np.sqrt(2*np.pi)/K\n",
    "        while (abs(x0-x1) > tol*np.sqrt(T)) and (j < maxiter):\n",
    "            x0 = x1\n",
    "            d1 = -p/x1+0.5*x1\n",
    "            x1 = x1-(K*norm.cdf(x1-d1)-norm.cdf(-d1)-value)*np.sqrt(2*np.pi)*np.exp(0.5*d1**2)\n",
    "            j += 1\n",
    "        return x1/np.sqrt(T)\n",
    "\n",
    "# vectorized version\n",
    "blackscholes_impv = np.vectorize(blackscholes_impv_scalar, excluded={'callput', 'tol', 'maxiter'})\n",
    "\n",
    "# Example\n",
    "blackscholes_impv(K=95, T=0.25, S=100, value=7, callput='call')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quartic_kernel(x):\n",
    "    x = np.clip(x, -1, 1)\n",
    "    return (x+1)**2*(1-x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
